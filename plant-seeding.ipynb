{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import cv2, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import keras\n",
    "\n",
    "from keras.layers import Flatten, Dense, Conv2D ,Dropout, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "from jupyterthemes import jtplot\n",
    "from glob import glob\n",
    "import h5py\n",
    "\n",
    "def get_classes():\n",
    "    return ['Black-grass',\n",
    "            'Charlock',\n",
    "            'Cleavers',\n",
    "            'Common Chickweed',\n",
    "            'Common wheat',\n",
    "            'Fat Hen',\n",
    "            'Loose Silky-bent',\n",
    "            'Maize',\n",
    "            'Scentless Mayweed',\n",
    "            'Shepherds Purse',\n",
    "            'Small-flowered Cranesbill',\n",
    "            'Sugar beet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_for_plant(image):\n",
    "    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    sensitivity = 35\n",
    "    lower_hsv = np.array([60 - sensitivity, 100, 50])\n",
    "    upper_hsv = np.array([60 + sensitivity, 255, 255])\n",
    "\n",
    "    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def segment_plant(image):\n",
    "    mask = create_mask_for_plant(image)\n",
    "    output = cv2.bitwise_and(image, image, mask = mask)\n",
    "    return output\n",
    "\n",
    "def sharpen_image(image):\n",
    "    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
    "    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n",
    "    return image_sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sharp_image(image):\n",
    "    image = image.astype('uint8')\n",
    "    image_mask = create_mask_for_plant(image)\n",
    "    image_segmented = segment_plant(image)\n",
    "    image_sharpen = sharpen_image(image_segmented)\n",
    "    return image_sharpen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    x = np.array(x, np.float32) / 255.\n",
    "    #x = x.transpose((0, 1, 2, 3))\n",
    "    print(\"Shape:\", x.shape)\n",
    "    return x\n",
    "\n",
    "def get_image(path, img_width=48, img_height=48):\n",
    "    img = cv2.imread(path)\n",
    "    return cv2.resize(img, (img_width, img_height), fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def load_train(path, categories, img_width, img_height):\n",
    "    X_train, y_train, filenames = [], [], []\n",
    "    for folder in categories:\n",
    "        idx = categories.index(folder)\n",
    "        print(\"ID {}: Load {}\".format(idx, folder))\n",
    "        fullpath = os.path.join(path, folder)\n",
    "        for fl in os.listdir(fullpath):\n",
    "            filename = os.path.basename(fl)\n",
    "            img_path = os.path.join(fullpath, filename)\n",
    "            img = get_image(img_path, img_width, img_height)\n",
    "            img = get_sharp_image(img)\n",
    "            X_train.append(img)\n",
    "            filenames.append(filename)\n",
    "            y_train.append(idx)\n",
    "    return X_train, y_train, filenames\n",
    "\n",
    "def load_test(path, img_width, img_height):\n",
    "    X, filenames = [], []\n",
    "    for fl in sorted(os.listdir(path)):\n",
    "        filename = os.path.basename(fl)\n",
    "        img_path = os.path.join(path, filename)\n",
    "        img = get_image(img_path, img_width, img_height)\n",
    "        img = get_sharp_image(img)\n",
    "        X.append(img)\n",
    "        filenames.append(filename)\n",
    "    return X, filenames\n",
    "\n",
    "def get_train(path, categories, img_width, img_height):\n",
    "    X_train, y_train, filenames = load_train(path, categories, img_width, img_height)\n",
    "    X_train = normalize(X_train)\n",
    "    y_train = np.array(y_train, dtype=np.uint8)\n",
    "    return X_train, y_train, filenames\n",
    "\n",
    "def get_test(path, img_width, img_height):\n",
    "    X_test, filenames = load_test(path, img_width, img_height)\n",
    "    X_test = normalize(X_test)\n",
    "    return X_test, filenames\n",
    "\n",
    "def create_submission(preds, ids, output_path=\"./\", filename=\"test\", isSubmission=False):\n",
    "    df = pd.DataFrame({\"file\": pd.Series(ids), \"species\": pd.Series(preds)})\n",
    "    csvfile = filename\n",
    "    if isSubmission:\n",
    "        now = datetime.datetime.now()\n",
    "        csvfile = \"submission_\" + filename + \"_\" + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    df.to_csv(output_path + csvfile + \".csv\", index=False)\n",
    "    return df\n",
    "    \n",
    "def to_csv_ens(preds_true, preds, ids, classes, output_path=\"./\", filename=\"test\"):\n",
    "    df1 = pd.DataFrame({\"file\": pd.Series(ids), \"species\": pd.Series(preds_true)})\n",
    "    df2 = pd.DataFrame(preds, columns=classes)\n",
    "    df = pd.concat([df1, df2], axis=1)\n",
    "    df.to_csv(output_path + filename + \".csv\", index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_model(model):\n",
    "    last_conv_idx = [i for i, layer in enumerate(model.layers) if type(layer) is Conv2D][-1]\n",
    "    layers = model.layers[:last_conv_idx+1]\n",
    "    return Model(inputs=model.input, outputs=layers[-1].output)\n",
    "\n",
    "def stack_on_top(p, model):\n",
    "    inp = model.output\n",
    "    x = MaxPooling2D()(inp)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Dropout(p / 4)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(p)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(p / 2)(x)\n",
    "    y = Dense(len(get_classes()), activation='softmax')(x)\n",
    "    model = Model(inputs=[model.input], outputs=[y])\n",
    "    return model\n",
    "\n",
    "def get_VGG16(input_shape=(128, 128, 3)):\n",
    "    model = keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet', input_tensor=None, input_shape=input_shape, pooling='avg', classes=1000)\n",
    "\n",
    "#     model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    model = create_conv_model(model)\n",
    "    model = stack_on_top(0.6, model)\n",
    "    optimizer = Adam(1e-4)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "# Input and  dimensions\n",
    "img_width, img_height = (150, 150)\n",
    "input_shape = (img_width, img_height, 3)\n",
    "# Modelname\n",
    "modelname = 'VGG19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(path):\n",
    "    early_stop = EarlyStopping('val_loss', patience=5, mode=\"min\")\n",
    "    model_ckpt = ModelCheckpoint(path, save_best_only=True)\n",
    "    return [early_stop, model_ckpt]\n",
    "\n",
    "def image_augmetation(X, y, batch_size=32):\n",
    "    datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True,\n",
    "                                 width_shift_range=0.1, height_shift_range=0.1,\n",
    "                                 zoom_range=0.1, rotation_range=90)\n",
    "    datagen.fit(X)\n",
    "    return datagen.flow(X, y, batch_size=batch_size, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, epochs=1, batch_size=32):\n",
    "    # y categorical\n",
    "    y_true = np_utils.to_categorical(y, len(get_classes()))\n",
    "\n",
    "    # Split train/test data\n",
    "    trX, teX, trY, teY = train_test_split(X, y_true, test_size=0.20, random_state=SEED)\n",
    "\n",
    "    # Image augmentation\n",
    "    gen = image_augmetation(trX, trY)\n",
    "\n",
    "    # Create model\n",
    "    model = get_VGG16(input_shape)\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(X, y_true, epochs=epochs, batch_size=batch_size, shuffle=True, verbose=1)\n",
    "\n",
    "    # Fit model (generator)\n",
    "#     try:\n",
    "#         model.fit_generator(gen, epochs=epochs,\n",
    "#               steps_per_epoch=len(X)/batch_size,\n",
    "#               validation_data=(teX, teY),\n",
    "#               callbacks=get_callbacks(path='models/' + modelname + '-{epoch:02d}-{val_loss:.3f}' +'.h5')\n",
    "#               )\n",
    "#         # Save model\n",
    "#         model.save('models/' + modelname + '.h5')\n",
    "#     except:\n",
    "#         # Save model on keyboard abort\n",
    "#         model.save('models/' + modelname + '_OnExit' + '.h5')\n",
    "\n",
    "    print(\"Model saved.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID 0: Load Black-grass\n",
      "ID 1: Load Charlock\n",
      "ID 2: Load Cleavers\n",
      "ID 3: Load Common Chickweed\n",
      "ID 4: Load Common wheat\n",
      "ID 5: Load Fat Hen\n",
      "ID 6: Load Loose Silky-bent\n",
      "ID 7: Load Maize\n"
     ]
    }
   ],
   "source": [
    "# Get label encoder\n",
    "lb = LabelBinarizer()\n",
    "lbenc = lb.fit(get_classes())\n",
    "\n",
    "# Get train data\n",
    "X_train, y_train, train_filenames = get_train('train', list(lbenc.classes_), img_width, img_height)\n",
    "\n",
    "\n",
    "# Create and train model\n",
    "model = train(X_train, y_train, epochs=30, batch_size=32)\n",
    "\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++++\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test data\n",
    "X_test, X_test_id = get_test('test', img_width, img_height)\n",
    "# Predict on test data\n",
    "preds = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(lbenc.inverse_transform(preds), X_test_id, output_path=\"submissions/\", filename='8', isSubmission=True)\n",
    "print('Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
